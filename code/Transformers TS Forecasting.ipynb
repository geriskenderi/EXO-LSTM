{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.max_open_warning':0})\n",
    "matplotlib.use(\"agg\")\n",
    "# Add path to transformer code in the syspath in order to recognize the modules and import them\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../code/LSTM_TRANSF/Trasformer/'))\n",
    "from transformer.decoder import Decoder\n",
    "from transformer.multihead_attention import MultiHeadAttention\n",
    "from transformer.positional_encoding import PositionalEncoding\n",
    "from transformer.pointerwise_feedforward import PointerwiseFeedforward\n",
    "from transformer.encoder_decoder import EncoderDecoder\n",
    "from transformer.encoder import Encoder\n",
    "from transformer.encoder_layer import EncoderLayer\n",
    "from transformer.decoder_layer import DecoderLayer\n",
    "from transformer.noam_opt import NoamOpt\n",
    "from transformer.batch import subsequent_mask\n",
    "from transformer.flow import run_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformer.decoder.Decoder"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GeneratorTS(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(GeneratorTS, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab, )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.proj(x)\n",
    "\n",
    "\n",
    "def make_model(src_vocab, tgt_vocab, N=6,\n",
    "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadAttention(h, d_model)\n",
    "    ff = PointerwiseFeedforward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn),\n",
    "                             c(ff), dropout), N),\n",
    "        nn.Sequential(NewEmbed(src_vocab, d_model), c(position)),\n",
    "        nn.Sequential(NewEmbed(src_vocab, d_model), c(position)),\n",
    "        GeneratorTS(d_model, tgt_vocab))\n",
    "\n",
    "    # This was important from their code.\n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model\n",
    "\n",
    "\n",
    "class NewEmbed(nn.Module):\n",
    "    def __init__(self, vocab, d_model):\n",
    "        super(NewEmbed, self).__init__()\n",
    "        # lut => lookup table\n",
    "        self.lut = nn.Linear(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "\n",
    "\n",
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "\n",
    "    def __init__(self, src, trg=None):\n",
    "        self.src = src\n",
    "        # self.src_mask = Variable(torch.ones(src.shape[:-1]))\n",
    "        # self.src_mask2 = (src != pad).unsqueeze(-2)\n",
    "        self.src_mask = torch.ones(src.shape[:-1]).unsqueeze(-2)\n",
    "\n",
    "        if trg is not None:\n",
    "            self.trg_old = torch.cat((torch.ones((trg.shape[0], 1, trg.shape[-1])) * -1, trg), 1)\n",
    "            self.trg = self.trg_old[:, :-1]\n",
    "            self.trg_y = self.trg_old[:, 1:]\n",
    "            self.trg_mask = self.make_std_mask(self.trg, -2)\n",
    "            self.ntokens = trg.shape[0] * trg.shape[1]\n",
    "        if cuda:\n",
    "            self.src = self.src.cuda()\n",
    "            self.src_mask = self.src_mask.cuda()\n",
    "            self.trg = self.trg.cuda()\n",
    "            self.trg_y = self.trg_y.cuda()\n",
    "            self.trg_mask = self.trg_mask.cuda()\n",
    "\n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt[:, :, 0] != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & (\n",
    "            subsequent_mask(tgt.size(-2)).type_as(tgt_mask.data))\n",
    "        return tgt_mask\n",
    "\n",
    "\n",
    "def make_batch(src, tgt, batch_size, permu=True):\n",
    "    i = 0\n",
    "\n",
    "    perm = np.random.permutation(src.shape[0])\n",
    "    if permu:\n",
    "        src = src[perm, :]\n",
    "        tgt = tgt[perm, :]\n",
    "    while i < src.shape[0]:\n",
    "        yield Batch(torch.from_numpy(src[i:i + batch_size, :]),\n",
    "                    torch.from_numpy(tgt[i:i + batch_size, :]))\n",
    "        i += batch_size\n",
    "\n",
    "\n",
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "\n",
    "    def __call__(self, x, y, norm):\n",
    "        if self.opt is not None:\n",
    "            self.opt.optimizer.zero_grad()\n",
    "\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(x, y[:, :, 0:1])\n",
    "\n",
    "        if self.opt is not None:\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "\n",
    "        return loss.data.item() * norm\n",
    "\n",
    "\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol, ys_meta):\n",
    "    memory = model.encode(src.unsqueeze(0), src_mask.unsqueeze(0))\n",
    "    ys = torch.ones(1, 1, src.shape[-1]).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len - 1):\n",
    "        out = model.decode(memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data))\n",
    "        val_out = model.generator(out)\n",
    "        # _, next_word = torch.max(prob, dim=1)\n",
    "        # next_word = next_word.data[0]\n",
    "        ys = torch.cat([ys, torch.cat((val_out, ys_meta[i, 1:].unsqueeze(0)), dim=1).unsqueeze(0)], dim=1)\n",
    "    return ys\n",
    "\n",
    "\n",
    "def greedy_decode_batch(model, src, src_mask, max_len, start_symbol, ys_meta):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(src.shape[0], 1, src.shape[-1]).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len - 1):\n",
    "        out = model.decode(memory, src_mask, ys, subsequent_mask(ys.size(1)).type_as(src.data))\n",
    "        val_out = model.generator(out)[:, -1]\n",
    "        # _, next_word = torch.max(prob, dim=1)\n",
    "        # next_word = next_word.data[0]\n",
    "        ys = torch.cat([ys, torch.cat((val_out.unsqueeze(-1), ys_meta[:, i, 1:].unsqueeze(1)), dim=2)], dim=1)\n",
    "    return ys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########\n",
    "\n",
    "pretrained = False\n",
    "cuda = True\n",
    "cuda = cuda and torch.cuda.is_available()\n",
    "\n",
    "d_total = pd.read_csv(\"Dati Negozi/ALBIG_elaborato.csv\",delimiter=\",\", parse_dates=[0], index_col=0)\n",
    "\n",
    "#d_2008 = pd.read_csv(\"ERCOT/2008.csv\", delimiter=\";\", decimal=\",\", parse_dates=[0], index_col=0)\n",
    "#d_2009 = pd.read_csv(\"ERCOT/2009.csv\", delimiter=\";\", decimal=\",\", parse_dates=[0], index_col=0)\n",
    "#d_2010 = pd.read_csv(\"ERCOT/2010.csv\", delimiter=\";\", decimal=\",\", parse_dates=[0], index_col=0)\n",
    "#d_2011 = pd.read_csv(\"ERCOT/2011.csv\", delimiter=\";\", decimal=\",\", parse_dates=[0], index_col=0)\n",
    "#d_2012 = pd.read_csv(\"ERCOT/2012.csv\", delimiter=\";\", decimal=\",\", parse_dates=[0], index_col=0)\n",
    "#d_2013 = pd.read_csv(\"ERCOT/2013.csv\", delimiter=\";\", decimal=\",\", parse_dates=[0], index_col=0)\n",
    "#d_2014 = pd.read_csv(\"ERCOT/2014.csv\", delimiter=\";\", decimal=\",\", parse_dates=[0], index_col=0)\n",
    "d_2015 = pd.read_csv(\"ERCOT/2015.csv\", delimiter=\";\", decimal=\",\", parse_dates=[0], index_col=0)\n",
    "print(d_2015.shape)\n",
    "print(d_20XX.shape)\n",
    "\n",
    "#train = pd.concat([d_2008, d_2009, d_2010, d_2011, d_2012, d_2013, d_2014, d_2015])['ERCOT']\n",
    "train = pd.concat([d_2012, d_2013, d_2014, d_2015])['ERCOT'] #C'ERA ANCHE  all'inizio\n",
    "\n",
    "test = d_2016['ERCOT']\n",
    "\n",
    "train = train.resample('H').mean().fillna(method='pad')\n",
    "test = test.resample('H').mean().fillna(method='pad')\n",
    "\n",
    "tr_weekDay = pd.get_dummies(train.index.dayofweek, dtype=np.float32)\n",
    "tr_weekDay.index = train.index\n",
    "te_weekDay = pd.get_dummies(test.index.dayofweek, dtype=np.float32)\n",
    "te_weekDay.index = test.index\n",
    "\n",
    "tr_year = train.index.year\n",
    "te_year = test.index.year\n",
    "\n",
    "tr_month = train.index.month\n",
    "te_month = test.index.month\n",
    "\n",
    "tr_hour = train.index.hour\n",
    "te_hour = test.index.hour\n",
    "\n",
    "mean = train.values.mean()\n",
    "std  = train.values.std()\n",
    "tr_df = pd.DataFrame({'val': (train.values -mean)/std, 'year': tr_year.values, 'hour': tr_hour.values / 24,\n",
    "                      'ts': ((train.index - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta(\"1s\")).values},\n",
    "                     index=train.index.values, dtype=np.float32, columns=['val', 'year', 'hour', 'ts'])\n",
    "te_df = pd.DataFrame({'val': (test.values -mean)/ std, 'year': te_year.values, 'hour': te_hour.values / 24,\n",
    "                      'ts': ((test.index - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta(\"1s\")).values},\n",
    "                     index=test.index.values, dtype=np.float32, columns=['val', 'year', 'hour', 'ts'])\n",
    "\n",
    "tr_df = pd.concat([tr_df, tr_weekDay], axis=1)\n",
    "te_df = pd.concat([te_df, te_weekDay], axis=1)\n",
    "\n",
    "\n",
    "#atr = [x for x in range(11) if x != 3]\n",
    "atr = [0, 2, 4, 5, 6, 7, 8, 9, 10]\n",
    "#atr = [0]\n",
    "inp_tr = np.stack([tr_df.shift(i).values for i in range(12, 36)], axis=1)[36:, -1::-1, atr].copy()\n",
    "out_tr = np.stack([tr_df.shift(i).values for i in range(12)], axis=1)[36:, -1::-1, atr].copy()\n",
    "\n",
    "inp_te = np.stack([te_df.shift(i).values for i in range(12, 36)], axis=1)[36:, -1::-1, atr].copy()\n",
    "out_te = np.stack([te_df.shift(i).values for i in range(12)], axis=1)[36:, -1::-1, atr].copy()\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "model = make_model(inp_te.shape[-1], 1, N=6, d_model=512, h=8)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "model_opt = NoamOpt(512, 0.1, 2000,\n",
    "                    torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "# model_opt=torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "best_model_loss=np.inf\n",
    "if not pretrained:\n",
    "    for epoch in range(100):    #dovrebbe essere il for lunghissimo che non smette di allenare\n",
    "        model.train()           # alle 16.25 del 9/2/20 siamo a 78 cicli di allenamento ogni 10 epoche FINE: 00.33 del 10/2/20\n",
    "        run_epoch(make_batch(inp_tr, out_tr, 200), model,\n",
    "                  SimpleLossCompute(model.generator, criterion, model_opt))\n",
    "        model.eval()\n",
    "        eval_loss = run_epoch(make_batch(inp_te, out_te, 30), model,\n",
    "                              SimpleLossCompute(model.generator, criterion, None))\n",
    "        print(eval_loss)\n",
    "        if epoch % 1 == 0:\n",
    "            if eval_loss<best_model_loss:\n",
    "                torch.save(model.state_dict(), \"ercot_best_loss.pth\")\n",
    "                best_model_loss=eval_loss\n",
    "                with open(\"best_loss\",'w') as f1:\n",
    "                    f1.write(\"epoch, loss\\n %05i,%10.8f\"%(epoch,eval_loss))\n",
    "            f = open(\"eval loss.csv\", 'a')\n",
    "            f.write('%04i,%010.8f\\n' % (epoch, eval_loss))\n",
    "            f.close()\n",
    "\n",
    "            val_out = []\n",
    "            trg_out = []\n",
    "            for b in make_batch(inp_te, out_te, 30, False):\n",
    "                out = model.forward(b.src, b.trg, b.src_mask, b.trg_mask)\n",
    "                val_out.append(model.generator(out)[:, 0].cpu().data.numpy())\n",
    "                trg_out.append(b.trg_y[:, 0, 0].cpu().data.numpy())\n",
    "\n",
    "            val = np.concatenate(val_out, axis=0)\n",
    "            trg = np.concatenate(trg_out, axis=0)\n",
    "\n",
    "            x = list(range(1000))\n",
    "\n",
    "            val_plt = val[x]\n",
    "            trg_plt = trg[x]\n",
    "            plt.figure()\n",
    "            plt.plot(x, trg_plt, label='Ground truth')\n",
    "            plt.plot(x, val_plt, label='1d forecast')\n",
    "            plt.legend()\n",
    "            plt.savefig(\"plots_ercot/plot_epoch_%03i.png\" % (epoch))\n",
    "\n",
    "if pretrained:\n",
    "    model.load_state_dict(torch.load(\"ercot_ckp_195.pth\"))\n",
    "model.eval()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "val_out = []\n",
    "trg_out = []\n",
    "preds_out = []\n",
    "for b in make_batch(inp_te, out_te, 30, False):\n",
    "    out = model.forward(b.src, b.trg, b.src_mask, b.trg_mask)\n",
    "    val_out.append(model.generator(out)[:, 0].cpu().data.numpy())\n",
    "    trg_out.append(b.trg_y[:, :, 0].cpu().data.numpy())\n",
    "    # v = greedy_decode(model, b.src[k], b.src_mask[k], max_len=13, start_symbol=-1,ys_meta=b.trg_y[k])\n",
    "    v = greedy_decode_batch(model, b.src, b.src_mask, max_len=13, start_symbol=-1, ys_meta=b.trg_y)\n",
    "    vv = v.detach().cpu().numpy()\n",
    "    preds_out.append(vv[:, 1:, :])\n",
    "val = np.concatenate(val_out, axis=0)\n",
    "trg = np.concatenate(trg_out, axis=0)\n",
    "preds = np.concatenate(preds_out, axis=0)\n",
    "\n",
    "x = list(range(300))\n",
    "\n",
    "val_plt = val[x]\n",
    "trg_plt = trg[x,0]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, trg_plt, label='Ground truth')\n",
    "plt.plot(x, val_plt, label='1h forecast')\n",
    "plt.legend()\n",
    "plt.title(\"1h Forecast\")\n",
    "plt.savefig(\"plot_epoch_last_1h.png\")\n",
    "\n",
    "tt = test.values[25:][:val.shape[0]]\n",
    "mae = sm.tools.eval_measures.meanabs(((val[:, 0] * std)+mean).astype(int), tt)\n",
    "rmse = sm.tools.eval_measures.rmse(((val[:, 0] * std)+mean).astype(int), tt)\n",
    "\n",
    "print(\"MAE  1h: %10.4f\" % (mae))\n",
    "print(\"RMSE 1h: %10.4f\" % (rmse))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, trg[x,-1], label='Ground truth')\n",
    "plt.plot(x, preds[x,-1,0], label='12h forecast')\n",
    "plt.legend()\n",
    "plt.title(\"12h Forecast\")\n",
    "plt.savefig(\"plot_epoch_last_12h.png\")\n",
    "\n",
    "tt = test.values[36:][:preds.shape[0]]\n",
    "mae = sm.tools.eval_measures.meanabs(((preds[:,-1,0] * std)+mean).astype(int), tt)\n",
    "rmse = sm.tools.eval_measures.rmse(((preds[:,-1,0] * std)+mean).astype(int), tt)\n",
    "\n",
    "print(\"MAE  1h: %10.4f\" % (mae))\n",
    "print(\"RMSE 1h: %10.4f\" % (rmse))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
